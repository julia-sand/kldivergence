{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpHlh001Ss2O"
      },
      "source": [
        "##Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-RAK-Z8W2XN"
      },
      "outputs": [],
      "source": [
        "#install before running\n",
        "\n",
        "\n",
        "#from derivative import dxdt\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import pdflatex\n",
        "import matplotlib as mpl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#from mpl_toolkits import mplot3d\n",
        "import matplotlib.gridspec as gridspec\n",
        "#from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
        "from matplotlib import cm\n",
        "import matplotlib.patches as mpatches\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "import matplotlib.lines as mlines\n",
        "\n",
        "from scipy.ndimage import median_filter,generic_filter\n",
        "import scipy.ndimage as sc\n",
        "\n",
        "\n",
        "from scipy.interpolate import splrep, BSpline\n",
        "from scipy.interpolate import UnivariateSpline\n",
        "from scipy import interpolate\n",
        "from scipy import optimize\n",
        "import scipy.interpolate as sci\n",
        "\n",
        "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
        "\n",
        "from matplotlib.legend_handler import HandlerLine2D, HandlerTuple\n",
        "from matplotlib.legend_handler import HandlerBase\n",
        "#from matplotlib import collections\n",
        "\n",
        "\n",
        "\n",
        "#import ot\n",
        "from sklearn.neighbors import KernelDensity\n",
        "import numpy.random as npr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6NOHXAF3xR4"
      },
      "source": [
        "##Laundauer model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###KL DIVERGENCE\n",
        "Functions for the predicted cumulants and corrections for the marginal density of the position and the optimal protocol."
      ],
      "metadata": {
        "id": "TgA2O9ly-LUT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drwhvl0vmaEb"
      },
      "outputs": [],
      "source": [
        "#df_orig = pd.read_csv(\"ep_land4.csv\",index_col=0)\n",
        "path = \"results_kl_land44.csv\"\n",
        "#\"underdamped_kl_results_v1.csv\"\n",
        "data = pd.read_csv(path)#,index_col = 0)\n",
        "df_orig = pd.DataFrame(data)\n",
        "df = df_orig.rename({'ptx': 'rho'}, axis='columns')\n",
        "\n",
        "#fill infs and nans with zeros\n",
        "df.replace(np.inf, 0, inplace=True)\n",
        "df.replace(np.nan, 0, inplace=True)\n",
        "\n",
        "\n",
        "##PARAMETERS\n",
        "Tf = 5 #2#4\n",
        "epsilon = 0.2#np.sqrt(0.1)#0.2\n",
        "\n",
        "g = 0\n",
        "omega = 1\n",
        "beta = 1\n",
        "\n",
        "#decimal places for the time lookup.\n",
        "dps =  4#\n",
        "filter_delta = 20 #size of convolution filter to use\n",
        "\n",
        "#tolerance to zero.\n",
        "tol = 1e-10\n",
        "\n",
        "#constants\n",
        "def B_fn(Tf):\n",
        "  return -((1+g)/Tf)*np.tanh(omega*Tf/2)*(omega*np.tanh(Tf) - 2*np.tanh(omega*Tf/2))/(omega*np.tanh(omega*Tf/2) - 2*np.tanh(Tf))\n",
        "\n",
        "def A_fn(Tf):\n",
        "  return (1+g)*(1 - (((omega**2 - 4)*(np.tanh(omega*Tf/2)*np.tanh(Tf)))/(omega*Tf*(omega*np.tanh(omega*Tf/2)-2*np.tanh(Tf)))))\n",
        "\n",
        "T = Tf\n",
        "A_minus_B = (1+g)*(1-((2/(omega*T))*(np.tanh(omega*T/2))))\n",
        "\n",
        "A = A_fn(Tf)\n",
        "B = B_fn(Tf)\n",
        "\n",
        "alpha = np.sqrt((1+g)*A)\n",
        "\n",
        "#clips values close to zero to prevent errors in logarithms\n",
        "def zchop(a,tol = tol):\n",
        "  #input: vector a\n",
        "  #output: vector with values close to zero clipped.\n",
        "  a[np.abs(a) < tol] = 0.0\n",
        "  return a\n",
        "\n",
        "#get values of t2\n",
        "t2_vec = np.array(df.t.unique())\n",
        "t2_vec.sort()\n",
        "\n",
        "#compute mean and variance using all data\n",
        "mean_0 = np.zeros(len(t2_vec))\n",
        "var_0 = np.zeros(len(t2_vec))\n",
        "\n",
        "for t2 in enumerate(t2_vec):\n",
        "  #get q-axis\n",
        "  q_temp = df[df.t == t2[1]].x.to_numpy()\n",
        "  #get rho\n",
        "  rho_temp = df[df.t == t2[1]].rho.to_numpy()\n",
        "  #compute first order mean and var as functions of t2\n",
        "  mean_0[t2[0]] = np.trapz(q_temp*rho_temp,q_temp)\n",
        "  var_0[t2[0]] = np.trapz((q_temp**2)*rho_temp,q_temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cut the x-axis so that each is of the same length.\n",
        "#This should only remove where there is no mass, ie rho = 0\n",
        "xmin = -5\n",
        "xmax = 5\n",
        "\n",
        "for t2 in t2_vec:\n",
        "  xmin = np.maximum(xmin,np.min(df[df.t==t2].x))\n",
        "  xmax = np.minimum(xmax,np.max(df[df.t==t2].x))\n",
        "\n",
        "#delete edge rows\n",
        "df.drop(df[df.x < xmin].index, inplace=True)\n",
        "df.drop(df[df.x > xmax].index, inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "yCqPCUm79L_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OKwOLZbkxWd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#get qaxis\n",
        "q_axis = df[df.t == 0].x.to_numpy()\n",
        "\n",
        "#function to get rho at time t0.\n",
        "def rho(t0):\n",
        "  t2 = round(t0*(epsilon**2),dps)\n",
        "  rho_temp = df[df.t==t2].rho.to_numpy()\n",
        "  return zchop(rho_temp)\n",
        "\n",
        "#get all xcoords where there is probability mass\n",
        "def get_rhomask(t0):\n",
        "  return np.where(rho(t0)>0)\n",
        "\n",
        "#generate vecotr of t0 from values of t2\n",
        "times_t0 = np.round(t2_vec/(epsilon**2),dps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEK73WqsTVGs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def b(t0,g=0):\n",
        "  omega = 1#np.sqrt((1+g)/g)\n",
        "\n",
        "  denom1 =np.cosh(T)*np.sinh(omega*T) -(2*np.sinh(T)*np.cosh(omega*T)+2*np.sinh(T))/omega\n",
        "\n",
        "  num3 = np.sinh(omega*(T-t0))*np.exp(-T)\n",
        "  num4 = np.sinh(omega*t0)*np.exp(T) - np.sinh(omega*T)*np.exp(2*t0 - T)\n",
        "  return (1/denom1)*(num3+num4)\n",
        "\n",
        "def a_minus_b2(t0,g=0):\n",
        "  omega = 1#np.sqrt((1+g)/g)\n",
        "\n",
        "  return 1 -(np.cosh(omega*t0)+np.cosh(omega*(t0-T)))/(1+np.cosh(T*omega))\n",
        "\n",
        "def a(t0,g=0):\n",
        "\n",
        "  return a_minus_b2(t0,g) + b(t0,g)\n",
        "\n",
        "def b_dot(t0,g=0):\n",
        "  omega = 1#np.sqrt((1+g)/g)\n",
        "\n",
        "  denom1 =np.cosh(T)*np.sinh(omega*T) -(2*np.sinh(T)*np.cosh(omega*T)+2*np.sinh(T))/omega\n",
        "\n",
        "  num3 = -omega*np.cosh(omega*(T-t0))*np.exp(-T)\n",
        "  num4 = omega*np.cosh(omega*t0)*np.exp(T) - 2*np.sinh(omega*T)*np.exp(2*t0 - T)\n",
        "  return (1/denom1)*(num3+num4)\n",
        "  \"\"\"\n",
        "  omega = np.sqrt((1+g)/g)\n",
        "\n",
        "  denom1 = omega*np.cosh(T) - 2*(np.sinh(T)/np.tanh(omega*T/2))\n",
        "  denom2 = np.sinh(omega*T)\n",
        "\n",
        "  num1 = omega*np.sinh(omega*t0) - 2*np.exp(2*t0)\n",
        "  num2 = omega*(np.exp(2*T) - np.cosh(omega*T))*np.cosh(omega*t0)\n",
        "\n",
        "  return omega*np.exp(-T)*((num1/denom1) + (num2/denom1)/denom2)\n",
        "  \"\"\"\n",
        "\n",
        "def a_dot(t0,g=0):\n",
        "  omega = 1#np.sqrt((1+g)/g)\n",
        "\n",
        "  term1 = -(np.sinh(omega*t0)+np.sinh(omega*(t0-T)))/(1+np.cosh(T*omega))\n",
        "\n",
        "  return b_dot(t0,g) + omega*term1\n",
        "\n",
        "#mean and variances\n",
        "def mean_t0(t0):\n",
        "\n",
        "  t2 = round(t0*(epsilon**2),dps)\n",
        "  index_mean = np.where(t2_vec==t2)[0][0]\n",
        "\n",
        "  return mean_0[index_mean]\n",
        "\n",
        "def var_t0(t0):\n",
        "\n",
        "  t2 = round(t0*(epsilon**2),dps)\n",
        "  index_mean = np.where(t2_vec==t2)[0][0]\n",
        "\n",
        "  return var_0[index_mean]\n",
        "\n",
        "#function to get sigma\n",
        "def sigma(t0):\n",
        "\n",
        "  t2 = round(t0*(epsilon**2),dps)\n",
        "  sigtemp = df[df.t==t2].sigma.to_numpy()\n",
        "\n",
        "  return sigtemp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0En39PnUgIc"
      },
      "outputs": [],
      "source": [
        "#derivative functions\n",
        "def dsigma(t0):\n",
        "  sigma_temp = sigma(t0)\n",
        "  idx = get_rhomask(t0)\n",
        "\n",
        "  sigma_vals = sigma_temp[idx]\n",
        "  q_vals = q_axis[idx]\n",
        "\n",
        "  dsig = np.gradient(sigma_vals,q_vals)\n",
        "  dsigout = generic_filter(dsig,sc.median,filter_delta,mode = \"nearest\")\n",
        "\n",
        "  dtemp = np.zeros(len(q_axis))\n",
        "  dtemp[idx] = dsigout\n",
        "\n",
        "  return dtemp\n",
        "\n",
        "def dfun(vals,qs):\n",
        "\n",
        "  dfun = np.gradient(vals,qs)\n",
        "\n",
        "  return generic_filter(dfun,sc.median,40,mode = \"nearest\")\n",
        "\n",
        "def dlogrho(t0):\n",
        "  logrho = np.log(rho(t0))\n",
        "\n",
        "  #get rid of nans\n",
        "  #interpolate only on non-zero vals of rho\n",
        "  idx = get_rhomask(t0)\n",
        "  logrho_temp = logrho[idx]\n",
        "  q_axis_temp = q_axis[idx]\n",
        "\n",
        "  #differentiate and filter without edges\n",
        "  dlogrho = np.gradient(logrho_temp,q_axis_temp)\n",
        "  filter_dlogrho = generic_filter(dlogrho,\n",
        "                 sc.median,filter_delta,mode=\"nearest\")\n",
        "\n",
        "  #put back into right place\n",
        "  dlogout = np.zeros(len(q_axis))\n",
        "  dlogout[idx] = filter_dlogrho\n",
        "\n",
        "  return dlogout\n",
        "\n",
        "def drho(t0):\n",
        "  rho_vals = rho(t0)\n",
        "\n",
        "  #interpolate only on non-zero vals of rho\n",
        "  idx = get_rhomask(t0)\n",
        "  rho_vals_temp = rho_vals[idx]\n",
        "  q_axis_temp = q_axis[idx]\n",
        "\n",
        "  drho = np.gradient(rho_vals_temp,q_axis_temp)\n",
        "  #set values outside of range to zero to prevent extrapolation error\n",
        "  drho_vals = np.zeros(len(q_axis))\n",
        "  drho_vals[idx] = generic_filter(drho,sc.median,filter_delta,mode=\"constant\")\n",
        "\n",
        "  return drho_vals\n",
        "\n",
        "def rho_dsigma_alpha_rho(t0):\n",
        "\n",
        "  rho_dsigma_alpha_rho = rho(t0)*dsigma(t0) + alpha*drho(t0)\n",
        "\n",
        "  #fill nan with zero\n",
        "  rho_dsigma_alpha_rho[np.isnan(rho_dsigma_alpha_rho)] = 0\n",
        "\n",
        "  return rho_dsigma_alpha_rho\n",
        "\n",
        "def dsigma_alpha_rho(t0):\n",
        "\n",
        "  dsigma_alpha_rho = dsigma(t0) + alpha*dlogrho(t0)\n",
        "\n",
        "  #fill nan with zero\n",
        "  dsigma_alpha_rho[np.isnan(dsigma_alpha_rho)] = 0\n",
        "\n",
        "  return dsigma_alpha_rho\n",
        "\n",
        "def rho_ddsigma_alpha_rho(t0):\n",
        "\n",
        "  #get drho\n",
        "  drhotemp = dlogrho(t0)\n",
        "\n",
        "  #remove zeros first\n",
        "  idx = get_rhomask(t0)\n",
        "  ddrhotemp = drhotemp[idx]\n",
        "  q_temp = q_axis[idx]\n",
        "  ddlogrho = np.gradient(ddrhotemp,q_temp)\n",
        "\n",
        "  ddlogrho = generic_filter(ddlogrho,sc.mean,filter_delta,mode=\"nearest\")\n",
        "\n",
        "  #get ddsigma\n",
        "  dsigtemp = dsigma(t0)\n",
        "  dsig_vals = dsigtemp[idx]\n",
        "  ddsigtemp = np.gradient(dsig_vals,q_temp)\n",
        "  #dfun(dsigtemp,q_axis)\n",
        "  #ddsig_add = ddsigtemp[~np.isnan(drhotemp)]\n",
        "\n",
        "  temp_out = alpha*ddlogrho + generic_filter(ddsigtemp,sc.mean,filter_delta,mode=\"nearest\")\n",
        "\n",
        "  temp_vals_out = np.zeros(len(q_axis))\n",
        "  temp_vals_out[idx] = temp_out\n",
        "\n",
        "  output_vals = temp_vals_out*rho(t0)\n",
        "  return generic_filter(output_vals,sc.mean,size=filter_delta,mode=\"constant\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxQh4RnE2g0G"
      },
      "outputs": [],
      "source": [
        "\n",
        "#compute cumulants and other functions\n",
        "def kappa(t0): #mu dot 1\n",
        "  integral = rho(t0) * dsigma(t0)\n",
        "  return -np.trapz(integral,q_axis)\n",
        "\n",
        "##\n",
        "def f11(t0):\n",
        "\n",
        "  rho_vals = rho(t0)\n",
        "\n",
        "  coeff1 = -a(t0)/A\n",
        "  num1 = rho_dsigma_alpha_rho(t0)\n",
        "\n",
        "  coeff2 = rho_vals *(B*a(t0) - A*b(t0))/(A*A_minus_B)\n",
        "   #(A-B))\n",
        "\n",
        "  return coeff1*num1 + coeff2*kappa(t0)\n",
        "\n",
        "##\n",
        "def calculate_df11(t0):\n",
        "  drho_vals = drho(t0)\n",
        "\n",
        "  coeff1 = -a(t0)/A\n",
        "  num1 = (drho_vals*dsigma_alpha_rho(t0)) + rho_ddsigma_alpha_rho(t0)\n",
        "\n",
        "  num1[np.isnan(num1)] = 0\n",
        "  num1[np.isinf(num1)] = 0\n",
        "\n",
        "  coeff2 = (B*a(t0) - A*b(t0))/(A*A_minus_B)\n",
        "\n",
        "  df11_out = coeff1*num1 + coeff2*(kappa(t0)*drho_vals)\n",
        "\n",
        "  return df11_out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#coefficients of the gradient of df11\n",
        "def coeff1_df11(t0):\n",
        "  coeff1 = -a(t0)/A\n",
        "  return coeff1\n",
        "\n",
        "def coeff2_df11(t0):\n",
        "  coeff2 = (B*a(t0) - A*b(t0))/(A*A_minus_B)\n",
        "  return coeff2\n",
        "\n",
        "#compute f02 at t0 and fixed t2.\n",
        "def f02_new(t0,g=g,T=T):\n",
        "\n",
        "  #fetch the constants in t2\n",
        "  t2_term1 = drho(t0)*dsigma_alpha_rho(t0) + rho_ddsigma_alpha_rho(t0)\n",
        "  t2_termrho = drho(t0)*kappa(t0)\n",
        "\n",
        "  term1 = -g*(coeff1_df11(t0)*t2_term1 + coeff2_df11(t0)*t2_termrho)\n",
        "\n",
        "  int_limit = np.where(times_t0==t0)[0][0] + 1\n",
        "  coeff1_df11_temp = [coeff1_df11(t)*t2_term1 for t in times_t0]\n",
        "  coeff2_df11_temp = [coeff2_df11(t)*t2_termrho for t in times_t0]\n",
        "\n",
        "  coeff1_int1 = (t0/T)*np.trapz(coeff1_df11_temp,times_t0,axis=0)\n",
        "  coeff2_int1 = (t0/T)*np.trapz(coeff2_df11_temp,times_t0,axis=0)\n",
        "\n",
        "  coeff1_int2 = np.trapz(coeff1_df11_temp[0:int_limit],times_t0[0:int_limit],axis=0)\n",
        "  coeff2_int2 = np.trapz(coeff2_df11_temp[0:int_limit],times_t0[0:int_limit],axis=0)\n",
        "\n",
        "  return term1 + (1+g)*(coeff1_int1 + coeff2_int1 - (coeff1_int2 + coeff2_int2))\n"
      ],
      "metadata": {
        "id": "ukqRzQ6KvrTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def conditional_mom_mean(t0): ##conditional momentum mean E(p|q)\n",
        "  return epsilon*f11(t0)\n",
        "\n",
        "def mom_mean(t0):\n",
        "  return epsilon*(a(t0)-b(t0))*kappa(t0)/A_minus_B\n",
        "\n",
        "#correction to the position marginal distribution\n",
        "def pos_correction(t0):\n",
        "  return rho(t0) + f02_new(t0)*(epsilon**2)\n",
        "\n",
        "#linear position cumulant\n",
        "#position mean\n",
        "def linear_position_cumulant(t0):\n",
        "  term1 = mean_t0(t0) + kappa(t0)*(epsilon**2)*g*(a(t0)-b(t0))/(A-B)\n",
        "  coeff2 = (epsilon**2)*(1+g)*kappa(t0)/(A-B)\n",
        "  int_limit = np.where(times_t0==t0)[0][0] + 1\n",
        "  ab_temp = [a(t)-b(t) for t in times_t0]\n",
        "  int1 = (t0/Tf)*np.trapz(ab_temp,times_t0,axis =0)\n",
        "  int2 = np.trapz(ab_temp[0:int_limit],times_t0[0:int_limit],axis =0)\n",
        "\n",
        "  return term1 - coeff2*(int1 - int2)\n",
        "\n",
        "#Cross correlation\n",
        "def script_k(t0):#varsigma dot\n",
        "  temp_vals = q_axis*rho_dsigma_alpha_rho(t0)\n",
        "  return -np.trapz(temp_vals,q_axis) - kappa(t0)*mean_t0(t0)\n",
        "\n",
        "def cross_correlation(t0):\n",
        "  return epsilon*a(t0)*script_k(t0)/A\n",
        "\n",
        "#position process variance\n",
        "def position_variance(t0):\n",
        "  term1 = var_t0(t0) - (mean_t0(t0)**2)\n",
        "  term2 = 2*(epsilon**2)*g*a(t0)*script_k(t0)/A\n",
        "\n",
        "  coeff3 = -2*script_k(t0)*(epsilon**2)*(1+g)/A\n",
        "\n",
        "  int_limit = np.where(times_t0==t0)[0][0] + 1\n",
        "  a_temp = [a(t) for t in times_t0]\n",
        "\n",
        "  int1 = (t0/Tf)*np.trapz(a_temp,times_t0,axis =0)\n",
        "  int2 = np.trapz(a_temp[0:int_limit],times_t0[0:int_limit],axis =0)\n",
        "  return term1 + term2 + coeff3*(int1 - int2)\n",
        "\n",
        "#momentum variance\n",
        "def momentum_variance(t0):\n",
        "\n",
        "  term1 = 1 - ((kappa(t0)*epsilon*a(t0)/A)**2)\n",
        "\n",
        "  int1 = np.trapz(rho_ddsigma_alpha_rho(t0),q_axis)/A\n",
        "  int_limit = np.where(times_t0==t0)[0][0] + 1\n",
        "\n",
        "  aexp_temp = [int1*a(t)*np.exp(-2*(t0-t)) for t in times_t0]\n",
        "  int2 = np.trapz(aexp_temp[0:int_limit],times_t0[0:int_limit],axis =0)\n",
        "\n",
        "  term2 = 2*(epsilon**2)*int2\n",
        "\n",
        "  sq_temp = ((dsigma_alpha_rho(t0))**2)*rho(t0)\n",
        "\n",
        "  term3 = ((epsilon*a(t0)/A)**2)*np.trapz(sq_temp,q_axis)\n",
        "\n",
        "  return term1 + term2 + term3\n"
      ],
      "metadata": {
        "id": "IQqPhsLt7jmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcJ0Uvj-HC_Z"
      },
      "outputs": [],
      "source": [
        "def calculate_distribution(t0):\n",
        "  rvals = rho(t0)+ (epsilon**2)*f02_new(t0)\n",
        "\n",
        "  #find normalising factor\n",
        "  norm_factor = np.trapz(np.abs(rvals),q_axis)\n",
        "\n",
        "  return rvals / norm_factor\n",
        "\n",
        "def calculate_optimal_drift(t0):\n",
        "\n",
        "  coeff1 = (a_dot(t0) + a(t0))/A\n",
        "\n",
        "  dlog_rho = dlogrho(t0)\n",
        "\n",
        "  term1 = (alpha*coeff1 - 1)*dlog_rho\n",
        "  term2 = coeff1*dsigma(t0)\n",
        "\n",
        "  coeff3 = kappa(t0)/(A*(A-B))\n",
        "  term3 = (B*a_dot(t0) - A*b_dot(t0)) + (B*a(t0) - A*b(t0))\n",
        "  opt_drift = term1 + term2 - coeff3*term3\n",
        "\n",
        "  opt_drift[np.isnan(opt_drift)] = 0\n",
        "  opt_drift[np.isinf(opt_drift)] = 0\n",
        "\n",
        "  return -opt_drift\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the pdfs and drifts for each t0 and adds them to the dataframe\n",
        "df['UDpdf'] = 1\n",
        "df['UDdrift'] = 1\n",
        "df['smooth_UDpdf'] = 1\n",
        "\n",
        "for t0 in times_t0:\n",
        "  t2 = round(t0*(epsilon**2),dps)\n",
        "  new_vals = calculate_distribution(t0)\n",
        "  smooth_dist = generic_filter(new_vals,sc.mean,100,mode=\"constant\")\n",
        "  drift_vals = calculate_optimal_drift(t0)\n",
        "  df.loc[df[df.t==t2].index,\"UDpdf\"] = new_vals\n",
        "  df.loc[df[df.t==t2].index,\"UDdrift\"] = drift_vals\n",
        "  df.loc[df[df.t==t2].index,\"smooth_UDpdf\"] = smooth_dist\n",
        "\n",
        "#function to get sigma\n",
        "def distribution(t0):\n",
        "  t2 = round(t0*(epsilon**2),dps)\n",
        "  dist = df[df.t==t2].UDpdf.to_numpy()\n",
        "  return dist\n",
        "\n",
        "#function to get sigma\n",
        "def optimal_drift(t0):\n",
        "  t2 = round(t0*(epsilon**2),dps)\n",
        "  drift_temp = df[df.t==t2].UDdrift.to_numpy()\n",
        "  return drift_temp\n",
        "\n",
        "\n",
        "#function to get sigma\n",
        "def smooth_distribution(t0):\n",
        "  t2 = round(t0*(epsilon**2),dps)\n",
        "  drift_temp = df[df.t==t2].smooth_UDpdf.to_numpy()\n",
        "  return drift_temp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgQqVDMv6_mx",
        "outputId": "b435c2a7-9364-4837-c451-d69a4249d8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-5da9f27e2f42>:24: RuntimeWarning: divide by zero encountered in log\n",
            "  logrho = np.log(rho(t0))\n",
            "<ipython-input-12-42578de61cfa>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[df[df.t==t2].index,\"UDpdf\"] = new_vals\n",
            "<ipython-input-12-42578de61cfa>:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[3.63560743 3.63560743 3.63560743 ... 3.63560743 3.63560743 3.63560743]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[df[df.t==t2].index,\"UDdrift\"] = drift_vals\n",
            "<ipython-input-12-42578de61cfa>:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[df[df.t==t2].index,\"smooth_UDpdf\"] = smooth_dist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"underdamped_kl_results_v3.csv\")"
      ],
      "metadata": {
        "id": "9Ad57Uhmjbxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###plots"
      ],
      "metadata": {
        "id": "RUDVpFqg-Trk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0-vo2ofkVWT"
      },
      "outputs": [],
      "source": [
        "##make the plots\n",
        "\n",
        "titlepad = 5\n",
        "titlex = 0.15\n",
        "titley = 0.85\n",
        "titlezorder = 1000\n",
        "titles = [\"(a)\",\"(b)\",\"(c)\",\"(d)\",\"(e)\",\"(f)\",\"(g)\",\"(h)\",\"(i)\",\"(j)\",\"(k)\",\"(l)\",\"(m)\",\"(n)\",\"(o)\",\"(p)\",\"(q)\"]\n",
        "time_titles = [\"$\\mathrm{t} = 0$\",\"$\\mathrm{t} = 0.25\\mathrm{t}_f$\",\n",
        "               \"$\\mathrm{t} = 0.4\\mathrm{t}_f$\",\"$\\mathrm{t} = 0.5\\mathrm{t}_f$\",\n",
        "               \"$\\mathrm{t} = 0.6\\mathrm{t}_f$\",\"$\\mathrm{t} = 0.7\\mathrm{t}_f$\",\n",
        "               \"$\\mathrm{t} = 0.8\\mathrm{t}_f$\",\"$\\mathrm{t} = 0.95\\mathrm{t}_f$\",\n",
        "               \"$\\mathrm{t} = \\mathrm{t}_f$\"]\n",
        "\n",
        "#dist title location\n",
        "disttitlex = -2.8\n",
        "disttitley = 0.52\n",
        "\n",
        "suptitlex = 0.07\n",
        "suptitley = 1.1\n",
        "\n",
        "dashlinezorder = 10\n",
        "\n",
        "#alpha for filled shapes\n",
        "shadingalpha = 1\n",
        "\n",
        "# Plotting the graphs)\n",
        "#COLORS\n",
        "c2 = \"#a6cee3\" #lightblue\n",
        "c3 = \"orange\" #\"#33a02c\" #dark green\n",
        "c1 = \"#1f78b4\" #darkblue\n",
        "c4 = \"#b2df8a\" #light green\n",
        "\n",
        "\n",
        "#set ylim for plot\n",
        "ymin = -30\n",
        "ymax = 20\n",
        "\n",
        "#xlims\n",
        "xlimmax = 3\n",
        "xlimmin = -3\n",
        "\n",
        "lw = 3\n",
        "\n",
        "#fontsizes\n",
        "xmax = 5\n",
        "fontsize = 22\n",
        "fontsizeticks = 18\n",
        "fontsizetitles = 22\n",
        "\n",
        "def format_axes(ax,fontsize):\n",
        "\n",
        "  ax.set_xlim((0,T))\n",
        "  ax.set_xlabel(r\"$\\mathrm{t}$\",fontsize = fontsizetitles)\n",
        "\n",
        "  #ax.set_xticklabels(labels = [0,1,2,3,4,5],fontsize=10)\n",
        "  ax.tick_params(axis='y', labelsize=fontsizeticks)\n",
        "  ax.tick_params(axis='x', labelsize=fontsizeticks)\n",
        "  return ax\n",
        "\n",
        "def format_drift(ax):\n",
        "\n",
        "  #ax.yaxis.tick_right()\n",
        "  ax.tick_params(axis='x', labelsize=fontsizeticks)\n",
        "  ax.tick_params(axis='y', labelsize=fontsizeticks)\n",
        "\n",
        "  ax.set_ylim((-30,30))\n",
        "  ax.set_xlim((xlimmin,xlimmax))\n",
        "  ax.set_xlabel(r\"$\\mathrm{q}$\",fontsize= fontsize,labelpad=7)\n",
        "\n",
        "##plot set-up\n",
        "def format_dist_axes(ax):\n",
        "\n",
        "  #ax.patch.set_alpha(0)\n",
        "  #ax.yaxis.tick_right()\n",
        "  ax.tick_params(axis='x', labelsize=fontsizeticks)\n",
        "  ax.tick_params(axis='y', labelsize=fontsizeticks)\n",
        "  #ax.tick_params(labeltop='off', labelright='off')\n",
        "\n",
        "  ax.set_ylim((-0.07,0.65))\n",
        "  ax.set_xlim((xlimmin,xlimmax))\n",
        "  ax.spines['bottom'].set_zorder(1000)\n",
        "\n",
        "  #ax.set_xticks([])\n",
        "  #ax.set_xticklabels([])\n",
        "  #ax.set_xlabel(r\"$\\mathrm{q}$\",fontsize= fontsize)\n",
        "\n",
        "def cleaner(arr,t0):\n",
        "\n",
        "  #masks nans and infs and returns a pair for plotting\n",
        "  #copy q axis\n",
        "  plotq = np.copy(q_axis)\n",
        "\n",
        "  masknan = get_rhomask(t0)\n",
        "\n",
        "  #this function removes nan's and the end points which come from the truncation of the gradients\n",
        "  arr = arr[np.min(masknan)+20:np.max(masknan)-20]\n",
        "  plotq = plotq[np.min(masknan)+20:np.max(masknan)-20]\n",
        "\n",
        "  return plotq, arr\n",
        "  #generic_filter(arr,sc.median,1,mode=\"constant\")\n",
        "\n",
        "\n",
        "\n",
        "#exact boundary conds\n",
        "p_initial = np.exp(-(q_axis-1)**4)\n",
        "p_final = np.exp(-(((q_axis**2 - 1)**2)))\n",
        "pi_norm = np.abs(np.trapz(p_initial,q_axis))\n",
        "pf_norm = np.abs(np.trapz(p_final,q_axis))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot params\n",
        "\n",
        "\n",
        "def plot_pdf_nucleation(tcurr,title,labels,loc):\n",
        "  '''This functions plots a distribution and labels it\n",
        "\n",
        "  input:\n",
        "  -tcurr: the time in terms of t0 to plot\n",
        "  -title: title of the graph (if using)\n",
        "  -label: label of the panel\n",
        "  -loc: location as a matplotlib subplot code (or gridspec)\n",
        "\n",
        "  output:\n",
        "  -plot in location given by loc with the overdamped(in orange)\n",
        "  and underdamped (in blue) of the marginal density of the position\n",
        "  '''\n",
        "\n",
        "  # t0 distribution\n",
        "  plt.subplot(loc)\n",
        "  plt.title(title, loc = \"center\", fontsize=fontsizetitles)\n",
        "\n",
        "  plt.plot(q_axis,rho(tcurr),color=\"orange\",lw=4)\n",
        "  plt.plot(q_axis,distribution(tcurr),color=c1,lw=3,  label =r\"$\\mathrm{t} = 0$\",zorder = 10000)\n",
        "\n",
        "  ax = plt.gca()\n",
        "  format_dist_axes(ax)\n",
        "  #ax.text(s = labels[0],fontweight =\"bold\",fontsize = fontsizetitles,x = disttitlex, y =disttitley,zorder = titlezorder)\n",
        "\n",
        "  #ax.set_xticklabels([])\n",
        "  ax.tick_params(axis='y', labelsize=fontsizeticks)\n"
      ],
      "metadata": {
        "id": "otXP62fLdX2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plot_pdf_nucleation(0,\"$\\mathrm{t} = 0$\",None,151)\n",
        "ax0 = plt.gca()\n",
        "ax0.fill_between(q_axis,p_initial/pi_norm,color = c2,alpha = shadingalpha)\n",
        "\n",
        "plot_pdf_nucleation(0.5*T,\"$\\mathrm{t} = 0.5\\ \\mathrm{t}_{\\mathrm{f}}$\",None,152)\n",
        "ax1 = plt.gca()\n",
        "ax1.set_yticklabels([])\n",
        "plot_pdf_nucleation(0.7*T,\"$\\mathrm{t} = 0.7\\ \\mathrm{t}_{\\mathrm{f}}$\",None,153)\n",
        "ax1 = plt.gca()\n",
        "ax1.set_yticklabels([])\n",
        "plot_pdf_nucleation(0.85*T,\"$\\mathrm{t} = 0.85\\ \\mathrm{t}_{\\mathrm{f}}$\",None,154)\n",
        "ax1 = plt.gca()\n",
        "ax1.set_yticklabels([])\n",
        "plot_pdf_nucleation(T,\"$\\mathrm{t} = \\mathrm{t}_{\\mathrm{f}}$\",None,155)\n",
        "\n",
        "plt.tight_layout()\n",
        "ax = plt.gca()\n",
        "ax.fill_between(q_axis,p_final/pf_norm,color = c2,alpha = shadingalpha)\n",
        "ax.set_yticklabels([])\n",
        "\n",
        "#make legend\n",
        "l0 = mlines.Line2D([], [], color=c1, lw = lw)\n",
        "l1 = mlines.Line2D([], [], color=\"orange\", lw = lw)\n",
        "p0 = mpatches.Patch(color = c2, alpha=shadingalpha)\n",
        "\n",
        "ax.legend([l0,l1,p0],[\"Underdamped\",\"Overdamped\",\"Assigned Boundary Conditions\"],\n",
        "              prop = {\"size\": fontsizetitles },\n",
        "              ncol = 4,\n",
        "              bbox_to_anchor=(-4.8, -0.05),\n",
        "              frameon = False)\n",
        "\n",
        "\n",
        "plt.savefig(\"KL_LAND_PDFS.png\")\n",
        "#plt.savefig(\"KL_LAND_PDFS.pdf\", format=\"pdf\")\n",
        "#plt.savefig(\"test1.eps\", format=\"eps\")\n",
        "\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "paVzylfXd1Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlVk2yGB_l2z"
      },
      "outputs": [],
      "source": [
        "#plot params\n",
        "\n",
        "#fontsizes\n",
        "xmax = 5\n",
        "fontsize = 28\n",
        "fontsizeticks = 22\n",
        "fontsizetitles = 28\n",
        "\n",
        "#set ylim for plot\n",
        "ymin = -30\n",
        "ymax = 30\n",
        "\n",
        "def plot_pair(tcurr,title,labels,gs,locy):\n",
        "  # t0 distribution\n",
        "  plt.subplot(gs[0,locy])\n",
        "  plt.title(title, loc = \"center\", fontsize=fontsizetitles)\n",
        "\n",
        "  plt.plot(q_axis,rho(tcurr),color=c3,lw=4)\n",
        "  plt.plot(q_axis,distribution(tcurr),color=c1,lw=3, label =r\"$\\mathrm{t} = 0$\",zorder = 10000)\n",
        "\n",
        "  #plt.plot(q_axis,rho(tcurr),color=c3,lw=4)\n",
        "  #plt.plot(q_axis,generic_filter(distribution(tcurr),sc.mean,100,mode=\"constant\"),color=c1,lw=3,  label =r\"$\\mathrm{t} = 0$\",zorder = 10000)\n",
        "\n",
        "\n",
        "  ax = plt.gca()\n",
        "  format_dist_axes(ax)\n",
        "  ax.text(s = labels[0],fontsize = fontsizetitles,x = disttitlex, y =disttitley,zorder = titlezorder)\n",
        "\n",
        "  ax.set_xticklabels([])\n",
        "  ax.tick_params(axis='y', labelsize=fontsizeticks)\n",
        "\n",
        "  drift0 = plt.subplot(gs[1, locy])\n",
        "  plot_data = cleaner(optimal_drift(tcurr),tcurr)\n",
        "\n",
        "  #this just removes the areas of low statistics rho < tol\n",
        "  qseries = plot_data[0]\n",
        "  yseries = plot_data[1]\n",
        "  sigma_data = cleaner(dsigma(tcurr),tcurr)\n",
        "  sigmaseries = -sigma_data[1]\n",
        "\n",
        "  ax0 = plt.gca()\n",
        "  format_drift(ax0)\n",
        "  ax0.text(s = labels[1],fontsize = fontsizetitles,x = disttitlex, y =25, zorder = titlezorder)\n",
        "\n",
        "  #series1a, = ax0.plot(qseries,yseries,color = c1,lw=lw,label = r\"Underdamped\",alpha=0.5,zorder = 100)\n",
        "  #series1b, = ax0.plot(qseries,sigmaseries,color = c3,lw=lw,label = r\"Overdamped\",alpha=0.5)\n",
        "  series1c, = ax0.plot(qseries,generic_filter(yseries,sc.mean,100,mode=\"nearest\"),color = c1,lw=lw,label = r\"Underdamped\",zorder = 10000)\n",
        "  series1d, = ax0.plot(qseries,generic_filter(sigmaseries,sc.mean,100,mode=\"nearest\"),color = c3,lw=lw,label = r\"Underdamped\",zorder = 10000)\n",
        "\n",
        "  if locy ==0:\n",
        "    ax.set_ylabel(r'$\\mathrm{f}_{\\mathrm{t}}(\\mathrm{q})$',fontsize = fontsizetitles,labelpad= 7)\n",
        "    ax0.set_ylabel(r'$-\\partial U_{\\mathrm{t}}(\\mathrm{q})$',fontsize = fontsizetitles,labelpad= -5)\n",
        "    if gs == gs0:\n",
        "      #for edges\n",
        "      ax.fill_between(q_axis,p_initial/pi_norm,color = c2,alpha = shadingalpha)\n",
        "  else:\n",
        "    ax0.set_yticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "\n",
        "  if locy ==-1 and gs == gs1:\n",
        "    ax.fill_between(q_axis,p_final/pf_norm,color = c2,alpha = shadingalpha)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#set up the gridspec\n",
        "\n",
        "fig = plt.figure(figsize = (18,24)) #figsize = (width,height)\n",
        "\n",
        "gs = gridspec.GridSpec(2, 1, height_ratios=[1,1],hspace=0.2)\n",
        "gs0 = gridspec.GridSpecFromSubplotSpec(2, 5, height_ratios=[1,2], subplot_spec=gs[0], hspace=0.1, wspace=0.05)\n",
        "gs1 = gridspec.GridSpecFromSubplotSpec(2, 5, height_ratios=[1,2], subplot_spec=gs[1], hspace=0.1, wspace=0.05)\n",
        "\n",
        "plot_pair(0,\"$\\mathrm{t} = 0$\",[\"(a)\",\"(f)\"],gs0,0)\n",
        "plot_pair(0.25*T,\"$\\mathrm{t} = 0.25\\ \\mathrm{t}_f$\",[\"(b)\",\"(g)\"],gs0,1)\n",
        "plot_pair(0.5*T,\"$\\mathrm{t} = 0.5\\ \\mathrm{t}_f$\",[\"(c)\",\"(h)\"],gs0,2)\n",
        "plot_pair(0.6*T,\"$\\mathrm{t} = 0.6\\ \\mathrm{t}_f$\",[\"(d)\",\"(i)\"],gs0,3)\n",
        "plot_pair(0.7*T,\"$\\mathrm{t} = 0.7\\ \\mathrm{t}_f$\",[\"(e)\",\"(j)\"],gs0,-1)\n",
        "\n",
        "plot_pair(0.8*T,\"$\\mathrm{t} = 0.8\\ \\mathrm{t}_f$\",[\"(k)\",\"(p)\"],gs1,0)\n",
        "plot_pair(0.85*T,\"$\\mathrm{t} = 0.85\\ \\mathrm{t}_f$\",[\"(l)\",\"(q)\"],gs1,1)\n",
        "plot_pair(0.9*T,\"$\\mathrm{t} = 0.9\\ \\mathrm{t}_f$\",[\"(m)\",\"(r)\"],gs1,2)\n",
        "plot_pair(0.95*T,\"$\\mathrm{t} = 0.95\\ \\mathrm{t}_f$\",[\"(n)\",\"(s)\"],gs1,3)\n",
        "plot_pair(T,\"$\\mathrm{t} = \\mathrm{t}_f$\",[\"(o)\",\"(t)\"],gs1,-1)\n",
        "\n",
        "#make legend\n",
        "l0 = mlines.Line2D([], [], color=c1, lw = lw)\n",
        "l1 = mlines.Line2D([], [], color=c3, lw = lw)\n",
        "p0 = mpatches.Patch(color = c2, alpha=shadingalpha)\n",
        "\n",
        "plt.legend([l0,l1,p0],[\"Underdamped\",\"Overdamped\",\"Assigned Boundary Conditions\"],\n",
        "              prop = {\"size\": fontsizeticks },\n",
        "              ncol = 3,\n",
        "              bbox_to_anchor=(0.4, -0.1),\n",
        "              frameon = False)\n",
        "\n",
        "\n",
        "#plt.savefig(\"kl_land_drift_v38.eps\")\n",
        "#plt.savefig(\"kl_land_drift_v38.pdf\")\n",
        "plt.savefig(\"kl_land_drift_v39.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "qWOmuEHZFL32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###cumulant plots"
      ],
      "metadata": {
        "id": "lxlTe5BbO5jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cumulant plots parameters\n",
        "#df = pd.read_csv(\"kl_gauss_T2_v8.csv\")\n",
        "ti = 0#np.min(times_t0)\n",
        "tf = T#np.max(times_t0)\n",
        "\n",
        "tlim = (ti,tf)\n",
        "\n",
        "####KL gauss\n",
        "xmax = tf#\n",
        "fontsize = 22\n",
        "fontsizeticks = 18\n",
        "fontsizetitles = 22\n",
        "\n",
        "titlepad = 10\n",
        "xtitle = 0.07\n",
        "ytitle = 0.88\n",
        "titlezorder = 1000\n",
        "\n",
        "\n",
        "lw = 3\n",
        "\n",
        "# Data for the graphs\n",
        "x = df.t\n",
        "titlepad = 5"
      ],
      "metadata": {
        "id": "MUuWsZUDGWTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GAUSSIAN PLOT\n",
        "\n",
        "# Create a 2x3 grid with different widths for the bottom row\n",
        "gs = gridspec.GridSpec(2, 6, width_ratios=[1, 1, 1, 1,1,1], height_ratios=[1, 1])\n",
        "\n",
        "# Plotting the graphs\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "#dashstyle\n",
        "dashstyle = \"dashed\"#(0,(5,10))\n",
        "dashstyle2 = \"dotted\"\n",
        "\n",
        "# pos mean\n",
        "plt.subplot(gs[0, 0:2])\n",
        "plt.title('(a)',fontweight = \"bold\",fontsize = fontsizetitles,x = xtitle,y = ytitle,pad = titlepad,zorder=titlezorder)\n",
        "plt.plot(x, df.p_pos_mean,color = c1,lw=lw)\n",
        "plt.plot(x, df.pos_mean,linestyle = dashstyle,color = c2,lw=lw)\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "ax.set_ylabel('Position Mean',fontsize = fontsizetitles)\n",
        "\n",
        "# pos var\n",
        "plt.subplot(gs[0, 2:4])\n",
        "plt.title('(b)',fontweight = \"bold\",fontsize = fontsizetitles,x = xtitle,pad = titlepad ,y = ytitle,zorder=titlezorder)\n",
        "plt.plot(x, df.p_pos_var,color =c1,lw=lw)\n",
        "plt.plot(x, df.pos_var,linestyle = dashstyle,color = c2,lw=lw)\n",
        "\n",
        "ax = plt.gca()\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "ax.set_ylabel('Position Variance',fontsize = fontsizetitles)\n",
        "\n",
        "###cross correlation\n",
        "plt.subplot(gs[0, 4:])\n",
        "plt.plot(x, df.p_cc,color = c1,lw=lw)\n",
        "plt.plot(x, df.cc,linestyle = dashstyle,color = c2,lw=lw)\n",
        "\n",
        "plt.title('(c)',fontweight = \"bold\",fontsize = fontsizetitles,x = xtitle,pad = titlepad ,y = ytitle,zorder=titlezorder)\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.set_xlim((0,xmax))\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "ax.set_ylabel('Cross Correlation',fontsize = fontsizetitles)\n",
        "\n",
        "# momvar\n",
        "mom_var = plt.subplot(gs[1, 3:])\n",
        "plt.plot(x, df.p_mom_var,color = c1,lw=lw)\n",
        "plt.plot(x, df.mom_var,linestyle = dashstyle,color = c2,lw=lw)\n",
        "plt.title('(e)',fontweight = \"bold\",fontsize = fontsizetitles,x = xtitle*(2/3), pad = titlepad ,y = ytitle,zorder=titlezorder)\n",
        "\n",
        "ax = plt.gca()\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "ax.set_ylabel('Momentum Variance',fontsize = fontsizetitles)\n",
        "\n",
        "\n",
        "plt.subplot(gs[1, :3])\n",
        "plt.title('(d)',fontweight = \"bold\",fontsize = fontsizetitles,x = xtitle*(2/3),pad = titlepad ,y = ytitle,zorder=titlezorder)\n",
        "ax = plt.gca()\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "\n",
        "pert1, = ax.plot(x, df.p_mom_mean,label =r\"Perturbative\",color = c1,lw=lw)\n",
        "npert1, = ax.plot(x, df.mom_mean,label =r\"Non-Perturbative\",linestyle = dashstyle,color = c2,lw=lw)\n",
        "\n",
        "ax.set_ylabel('Momentum Mean',fontsize = fontsizetitles)\n",
        "\n",
        "##make custom looking patch objects.???\n",
        "\n",
        "# Create a legend for the first line.\n",
        "first_legend = ax.legend([(pert1),(npert1)], [\"Perturbative\",\"Non Perturbative\"],\n",
        "                         handler_map={tuple: HandlerTuple(ndivide=None)},\n",
        "                         prop = {\"size\": fontsizetitles }, loc='lower center',frameon=False)#,handlelength=1.5)\n",
        "\n",
        "# Add the legend manually to the Axes.\n",
        "ax.add_artist(first_legend)\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# save the plot\n",
        "plt.savefig(\"kl_gauss_cumulants.eps\", format=\"eps\")\n",
        "plt.savefig(\"kl_gauss_cumulants.pdf\", format=\"pdf\")\n",
        "plt.savefig(\"kl_gauss_cumulants.png\", format=\"png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "YwwWlaLHWwMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9TRUQXecJbO"
      },
      "outputs": [],
      "source": [
        "#cumulants\n",
        "\n",
        "filename = \"kl_land_cumulants.eps\"\n",
        "format_type = \"eps\"\n",
        "\n",
        "\n",
        "# Plotting the graphs\n",
        "plt.figure(figsize=(15, 8))#, constrained_layout=True)\n",
        "\n",
        "# Create a 1x5 grid with different widths for the bottom row\n",
        "gs_cumulants = gridspec.GridSpec(2, 6, width_ratios=[1, 1, 1, 1,1,1], height_ratios=[1, 1])\n",
        "                              #hspace = 0.3,wspace = 2.3)\n",
        " #(1, 2, width_ratios=[6, 4], figure=fig)\n",
        "\n",
        "# position mean\n",
        "plt.subplot(gs_cumulants[0, 0:2])\n",
        "plt.plot(times_t0,  [linear_position_cumulant(t0) for t0 in times_t0],lw=lw)\n",
        "plt.title('(a)',fontsize = fontsizetitles,x = xtitle,y = ytitle,pad = titlepad,zorder=titlezorder)\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "ax.set_ylim((-0.05,1.2))\n",
        "ax.set_ylabel('Position Mean',fontsize = fontsizetitles)\n",
        "\n",
        "# position variance\n",
        "plt.subplot(gs_cumulants[0, 2:4])\n",
        "plt.plot(times_t0,  [position_variance(t0) for t0 in times_t0],lw=lw)\n",
        "plt.title('(b)',fontsize = fontsizetitles,x = xtitle,pad = titlepad ,y = ytitle,zorder=titlezorder)\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "ax.set_ylabel('Position Variance',fontsize = fontsizetitles)\n",
        "\n",
        "# cross corr\n",
        "plt.subplot(gs_cumulants[0, 4:])\n",
        "plt.plot(times_t0, [cross_correlation(t0) for t0 in times_t0],lw=lw)\n",
        "plt.title('(c)',fontsize = fontsizetitles,x = xtitle,pad = titlepad ,y = ytitle,zorder=titlezorder)\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "ax.set_ylabel('Cross Correlation',fontsize = fontsizetitles)\n",
        "\n",
        "\n",
        "# momentum mean\n",
        "plt.subplot(gs_cumulants[1,:3])\n",
        "plt.plot(times_t0, [mom_mean(t0) for t0 in times_t0],lw=lw)\n",
        "plt.title('(d)',fontsize = fontsizetitles,x = xtitle*(2/3),pad = titlepad ,y = ytitle,zorder=titlezorder)\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "ax.set_ylabel('Momentum Mean',fontsize = fontsizetitles)\n",
        "\n",
        "# momentum variance\n",
        "mom_var = plt.subplot(gs_cumulants[1, 3:])\n",
        "plt.plot(times_t0,  [momentum_variance(t0) for t0 in times_t0],lw=lw)\n",
        "plt.title('(e)',fontsize = fontsizetitles,x = xtitle*(2/3), pad = titlepad ,y = ytitle,zorder=titlezorder)\n",
        "ax = format_axes(plt.gca(),fontsize)\n",
        "ax.set_ylabel('Momentum Variance',fontsize = fontsizetitles)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.savefig(filename, format=format_type)\n",
        "plt.savefig(\"kl_land_cumulants.pdf\", format=\"pdf\")\n",
        "plt.savefig(\"kl_land_cumulants.png\", format=\"png\")\n",
        "\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Peak heights"
      ],
      "metadata": {
        "id": "r3e-aoDleRdA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQR03Rud5cMR"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import find_peaks\n",
        "\n",
        "plt.figure()\n",
        "series = smooth_distribution(5)\n",
        "peaks,properties = find_peaks(series, prominence=(0.0001, None))\n",
        "\n",
        "\n",
        "prominences = properties['prominences']\n",
        "\n",
        "plt.plot(series)\n",
        "plt.plot(peaks, series[peaks], \"x\")\n",
        "plt.fill_between(range(0,len(q_axis)),p_final/pf_norm,alpha= 0.3)\n",
        "\n",
        "plt.savefig(\"test_peaks.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILtF6MB_ClHj"
      },
      "outputs": [],
      "source": [
        "c5 = \"orange\"\n",
        "\n",
        "height_a = np.zeros(len(times_t0))\n",
        "height_b = np.zeros(len(times_t0))\n",
        "ODheight_a = np.zeros(len(times_t0))\n",
        "ODheight_b = np.zeros(len(times_t0))\n",
        "\n",
        "for t in enumerate(times_t0):\n",
        "  series = smooth_distribution(t[1])\n",
        "  rho_vals = rho(t[1])\n",
        "  peaks,props  = find_peaks(series,prominence=(0.01, None))\n",
        "  peaks_rho,props_rho  = find_peaks(rho_vals,prominence=(0.01, None))\n",
        "\n",
        "  prominences = props['prominences']\n",
        "  prominences_rho = props_rho['prominences']\n",
        "\n",
        "\n",
        "  ind1 = peaks[np.argmax(prominences)]\n",
        "  ind1_rho = peaks_rho[np.argmax(prominences_rho)]\n",
        "  try:\n",
        "    ind2 = peaks[np.argsort(prominences)[-2]]\n",
        "  except:\n",
        "    ind2 = ind1\n",
        "  try:\n",
        "    ind2_rho = peaks_rho[np.argsort(prominences_rho)[-2]]\n",
        "  except:\n",
        "    ind2_rho = ind1_rho\n",
        "\n",
        "\n",
        "  height_a[t[0]] = series[ind1]\n",
        "  height_b[t[0]] = series[ind2]\n",
        "  ODheight_a[t[0]] = rho_vals[ind1_rho]\n",
        "  ODheight_b[t[0]] = rho_vals[ind2_rho]\n",
        "\n",
        "plt.figure(figsize = (10,6))\n",
        "\n",
        "plt.plot(times_t0,height_a,lw=lw,color = c1,label = \"Underdamped\")\n",
        "plt.plot(times_t0,height_b,lw=lw,color = c1)\n",
        "plt.plot(times_t0,ODheight_a,lw=lw,color = c5,label = \"Underdamped\")\n",
        "plt.plot(times_t0,ODheight_b,lw=lw,color = c5)\n",
        "#plt.ylim((0.25,0.45))\n",
        "\n",
        "ax = plt.gca()\n",
        "format_axes(ax,fontsizeticks)\n",
        "ax.set_ylabel(\"Peak Height\", fontsize= fontsizetitles)\n",
        "\n",
        "l0 = mlines.Line2D([], [], color=c1, lw = lw)\n",
        "l1 = mlines.Line2D([], [], color=c3, lw = lw)\n",
        "l2 = mlines.Line2D([], [], color=\"orange\", lw = lw)\n",
        "\n",
        "ax.legend([l0,l2],[\"Underdamped\",\"Overdamped\"],\n",
        "              prop = {\"size\": fontsizetitles },\n",
        "              ncol = 1,\n",
        "              loc = \"upper left\",\n",
        "              #handler_map={tuple: HandlerTuple(ndivide=None)},\n",
        "              #bbox_to_anchor=(0.1, -0.1),\n",
        "              frameon = False)\n",
        "\n",
        "\n",
        "plt.savefig(\"kl_peakheights.eps\")\n",
        "plt.savefig(\"kl_peakheights.pdf\")\n",
        "plt.savefig(\"kl_peakheights.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Expansion and Contraction"
      ],
      "metadata": {
        "id": "wyvssFXR5eWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below creates the Figure 5 from the results obtained by calculations in KL Gauss notebooks."
      ],
      "metadata": {
        "id": "fpWGbdeTZYIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JA75FfYqJ0a-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "5e63b207-e67f-4048-8c1e-c6ec97c2474f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'kl_exco.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d4fc680a731d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"kl_exco.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath_con\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"kl_contraction.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_ex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_ex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata_con\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_con\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kl_exco.txt'"
          ]
        }
      ],
      "source": [
        "####expansion/contraction#############\n",
        "\n",
        "#path = \"ep_land20.csv\"\n",
        "path_ex = \"kl_exco.txt\"\n",
        "path_con = \"kl_contraction.txt\"\n",
        "data_ex = pd.read_csv(path_ex,skiprows = 0,sep =\" \")\n",
        "df_ex = pd.DataFrame(data_ex)\n",
        "data_con = pd.read_csv(path_con,skiprows = 0,sep =\" \")\n",
        "df_con = pd.DataFrame(data_con)\n",
        "\n",
        "path_ex0 = \"klExpansionUstar 0.txt\"\n",
        "path_con0 = \"klContractionUstar0.txt\"\n",
        "data_ex0 = pd.read_csv(path_ex0,skiprows = 1,sep =\" \",header =None)\n",
        "df_ex0 = pd.DataFrame(data_ex0)\n",
        "data_con0 = pd.read_csv(path_con0,skiprows = 1,sep =\" \",header = None)\n",
        "df_con0 = pd.DataFrame(data_con0)\n",
        "\n",
        "Taxis = np.linspace(3,10,7)\n",
        "Taxis_all = np.linspace(1,10,10)\n",
        "\n",
        "df_ex.columns = [\"KL\"]\n",
        "df_con.columns = [\"KL\"]\n",
        "\n",
        "df_ex0.columns = [\"T\",\"KL\"]\n",
        "df_con0.columns = [\"T\",\"KL\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PImF9K-KhzJC"
      },
      "outputs": [],
      "source": [
        "df_ex_1 = df_ex.drop(index=[1,2,3])\n",
        "df_con_1 = df_con.drop(index=[1,2,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68R3WPU99AV7"
      },
      "outputs": [],
      "source": [
        "\n",
        "#set ylim for plot\n",
        "ymin = -20\n",
        "ymax = 20\n",
        "\n",
        "\n",
        "####DISTRIUBUTIONS GO HERE\n",
        "####KL divergence gauss\n",
        "fig = plt.figure(figsize = (15,8))\n",
        "# Create a 1x5 grid with different widths for the bottom row\n",
        "\n",
        "# t0 distribution\n",
        "ex1, = plt.plot(Taxis,df_ex_1.KL/4,color=c1,lw=lw,  label =r\"Expansion\")\n",
        "con1, = plt.plot(Taxis,df_con_1.KL/4,color=c3,lw=lw,  label =r\"Contraction\")\n",
        "#ex0, = plt.plot(Taxis,df_ex0.KL,color=c2,lw=lw,  label =r\"Expansion, $U_{\\star}=0$\")\n",
        "#con0, = plt.plot(Taxis,df_con0.KL,color=c4,lw=lw,  label =r\"Contraction, $U_{\\star}=0$\")\n",
        "\n",
        "ax0 = plt.gca()\n",
        "#format_dist_axes(ax)\n",
        "ax0.set_ylabel(r'KL Divergence',fontsize = fontsizetitles)\n",
        "ax0.set_xlabel(r'$T$',fontsize = fontsizetitles)\n",
        "#ax.set_xticklabels([])\n",
        "ax0.tick_params(axis='y', labelsize=fontsizeticks)\n",
        "ax0.tick_params(axis='x', labelsize=fontsizeticks)\n",
        "ax0.set_xlim((2.8,10))\n",
        "#plt.yscale('log')#, linthresh=1)\n",
        "ax0.set_ylim((-0.05,0.4))\n",
        "\n",
        "ax0.legend( prop = {\"size\": fontsizetitles })\n",
        "\n",
        "# Show the plot\n",
        "plt.savefig(\"kl_exco.eps\", format=\"eps\")\n",
        "plt.savefig(\"kl_exco.pdf\", format=\"pdf\")\n",
        "plt.savefig(\"kl_exco.png\", format=\"png\")\n",
        "\n",
        "#files.download(\"kl_land_drift.eps\")\n",
        "#files.download(\"kl_land_drift.pdf\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxCvWPHaz1GS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "f1195034-7c08-440f-be3a-0fb3f5c264a8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Taxis_all' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c6bb9000403d>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# t0 distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mex1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTaxis_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKL\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34mr\"Expansion\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mcon1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTaxis_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_con\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKL\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34mr\"Contraction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mex0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTaxis_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_ex0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKL\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34mr\"Expansion, $U_{\\star}=0$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Taxis_all' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "#set ylim for plot\n",
        "ymin = -20\n",
        "ymax = 20\n",
        "\n",
        "####DISTRIUBUTIONS GO HERE\n",
        "####KL divergence gauss\n",
        "fig = plt.figure(figsize = (15,8))\n",
        "# Create a 1x5 grid with different widths for the bottom row\n",
        "\n",
        "# t0 distribution\n",
        "ex1, = plt.plot(Taxis_all,df_ex.KL/4,color=c1,lw=lw,  label =r\"Expansion\")\n",
        "con1, = plt.plot(Taxis_all,df_con.KL/4,color=c3,lw=lw,  label =r\"Contraction\")\n",
        "ex0, = plt.plot(Taxis_all,df_ex0.KL/4,color=c2,  label =r\"Expansion, $U_{\\star}=0$\")\n",
        "con0, = plt.plot(Taxis_all,df_con0.KL/4,color=c4,  label =r\"Contraction, $U_{\\star}=0$\")\n",
        "\n",
        "ax0 = plt.gca()\n",
        "#format_dist_axes(ax)\n",
        "ax0.set_ylabel(r'KL Divergence',fontsize = fontsizetitles)\n",
        "ax0.set_xlabel(r'$T$',fontsize = fontsizetitles)\n",
        "#ax.set_xticklabels([])\n",
        "ax0.tick_params(axis='y', labelsize=fontsizeticks)\n",
        "ax0.tick_params(axis='x', labelsize=fontsizeticks)\n",
        "ax0.set_xlim((0.8,10))\n",
        "plt.yscale('log')#, linthresh=1)\n",
        "#ax0.set_ylim((-0.05,1.4))\n",
        "\n",
        "ax0.legend( prop = {\"size\": fontsizetitles })\n",
        "\n",
        "# Show the plot\n",
        "plt.savefig(\"kl_exco_all.eps\", format=\"eps\")\n",
        "plt.savefig(\"kl_exco_all.pdf\", format=\"pdf\")\n",
        "plt.savefig(\"kl_exco_all.png\", format=\"png\")\n",
        "\n",
        "plt.close()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lxlTe5BbO5jt"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}